{
  "algo": "PPO",
  "env": "PongEnv",
  "framework": "torch",

  "num_env_runners": 4,
  "num_envs_per_env_runner": 1,
  "num_gpus": 0,

  "env_config": {
    "variant": "selfplay"
  },

  "rollout_fragment_length": "auto",
  "train_batch_size": 4096,
  "sgd_minibatch_size": 128,
  "lr": 0.0003,
  "num_sgd_iter": 4,

  "model": {
    "fcnet_hiddens": [256, 256],
    "fcnet_activation": "tanh"
  }
}